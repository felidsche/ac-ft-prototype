{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33a79acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out why this logical job is such an important feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27d32b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession, DataFrame, Window\n",
    "from pyspark.sql import functions as F\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d0d199",
   "metadata": {},
   "source": [
    "## create DataFrame from cleaned cluster trace Alibaba 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f5d6bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/25 09:32:08 WARN Utils: Your hostname, felix-Surface-Book resolves to a loopback address: 127.0.1.1; using 192.168.0.4 instead (on interface wlp3s0)\n",
      "22/02/25 09:32:08 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/felix/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/02/25 09:32:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "test_path = \"../../out/model/eval/final/GBT5CV3parall_priorFeat_tune_maxDepth_Iter_Bins_03inst777SeedVal/part-00000-fcf17f91-2e4e-4fb3-830d-921eb502fd93-c000.csv.gz\"\n",
    "master = \"local[2]\"  # use 2 cores\n",
    "app_name = \"analyse prediction of Alibaba 2018 cluster trace\"\n",
    "config = SparkConf().setAll([\n",
    "    ('spark.driver.memory', '3g')\n",
    "])\n",
    "spark_session = SparkSession.builder \\\n",
    "    .master(master) \\\n",
    "    .appName(app_name) \\\n",
    "    .config(conf=config) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "test = spark_session.read.csv(path=test_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9157b1fa",
   "metadata": {},
   "source": [
    "### read the data and reproduce the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48432806",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# read dataset\n",
    "data_name = \"batch_jobs_clean_03inst_1task_00015S_1F\"\n",
    "data_path = f\"../../out/clean/{data_name}/*.csv.gz\"\n",
    "data = spark_session.read.csv(data_path, header=True, inferSchema=True)\n",
    "# reproduce training set\n",
    "seed = 61\n",
    "fractions = {0: 0.50, 1: 0.50}\n",
    "training = data.sampleBy(col=\"labels\", fractions=fractions, seed=seed)\n",
    "# stratified (50/25/25) split to have 50% of the data for training, 25 for validation (hyper\n",
    "rest = data.subtract(training)\n",
    "fractions = {0: 0.25, 1: 0.25}\n",
    "validation = rest.sampleBy(col = \"labels\", fractions = fractions, seed = seed)\n",
    "test_raw = rest.subtract(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a7d800c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('task_name', 'string'),\n",
       " ('job_name', 'string'),\n",
       " ('task_id_num', 'int'),\n",
       " ('instance_num', 'int'),\n",
       " ('task_type', 'int'),\n",
       " ('status', 'string'),\n",
       " ('start_time', 'int'),\n",
       " ('end_time', 'int'),\n",
       " ('plan_cpu', 'double'),\n",
       " ('plan_mem', 'double'),\n",
       " ('map_reduce', 'string'),\n",
       " ('earliest', 'int'),\n",
       " ('sched_intv', 'int'),\n",
       " ('job_exec', 'int'),\n",
       " ('logical_job_name', 'string'),\n",
       " ('latest', 'int'),\n",
       " ('task_duration', 'int'),\n",
       " ('tts_task', 'int'),\n",
       " ('mtts_task', 'double'),\n",
       " ('ttf_task', 'int'),\n",
       " ('ttr_task', 'int'),\n",
       " ('reduce_checkpoint', 'int'),\n",
       " ('second_quant_checkpoint', 'int'),\n",
       " ('third_quant_checkpoint', 'int'),\n",
       " ('instance_name', 'string'),\n",
       " ('instance_task_type', 'int'),\n",
       " ('instance_status', 'string'),\n",
       " ('instance_start_time', 'int'),\n",
       " ('instance_end_time', 'int'),\n",
       " ('machine_id', 'string'),\n",
       " ('seq_no', 'int'),\n",
       " ('total_seq_no', 'int'),\n",
       " ('cpu_avg', 'double'),\n",
       " ('cpu_max', 'double'),\n",
       " ('mem_avg', 'double'),\n",
       " ('mem_max', 'double'),\n",
       " ('labels', 'int')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cccfac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+\n",
      "|logical_job_name| job_name|\n",
      "+----------------+---------+\n",
      "|            null|j_1514651|\n",
      "|            null| j_469896|\n",
      "|            null|j_1995375|\n",
      "|            null|j_1995375|\n",
      "|            null|j_1995375|\n",
      "+----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(\"logical_job_name\", \"job_name\").limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d832de6",
   "metadata": {},
   "source": [
    "### filter for the respective logical job and summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "de2e133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lj_most_imp = data.filter(\n",
    "    (F.col(\"logical_job_name\").contains(\"2678067\")) |  # most imp\n",
    "    (F.col(\"logical_job_name\").contains(\"3138253\")) |  # second most imp\n",
    "    (F.col(\"logical_job_name\").contains(\"2474299\"))    # third most imp\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "71e88977",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "218030"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lj_most_imp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1d46fc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 73:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|logical_job_name|\n",
      "+----------------+\n",
      "|     L_j_3138253|\n",
      "|     L_j_2474299|\n",
      "|     L_j_2678067|\n",
      "+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 73:=============================>                            (1 + 1) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lj_most_imp.select(\"logical_job_name\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2e2235fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lj_most_imp = lj_most_imp.groupBy(\"logical_job_name\").agg(\n",
    "    F.avg(\"plan_cpu\"),\n",
    "    F.avg(\"plan_mem\"),\n",
    "    F.avg(\"task_type\"),\n",
    "    F.avg(\"labels\")\n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7635bc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "latex = lj_most_imp.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "896f8075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrr}\n",
      "\\toprule\n",
      "{} & logical\\_job\\_name &  avg(plan\\_cpu) &  avg(plan\\_mem) &  avg(task\\_type) &  avg(labels) \\\\\n",
      "\\midrule\n",
      "0 &      L\\_j\\_3138253 &      89.407105 &       0.348577 &             1.0 &     0.599760 \\\\\n",
      "1 &      L\\_j\\_2474299 &      87.582682 &       0.375619 &             1.0 &     0.048997 \\\\\n",
      "2 &      L\\_j\\_2678067 &      98.829916 &       0.303328 &             1.0 &     0.914553 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed6696f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
